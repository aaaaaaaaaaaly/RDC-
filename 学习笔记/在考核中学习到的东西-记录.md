# 其他新知识-记录

**攻克史莱姆，未储备，需要学习的知识：**

- 特征工程的特征构造，特征选择
- 特征编码
- 模型评估方法



（以上知识有专门的markdown笔记记录，此处记录<u>其他</u>）

## 函数

### np.linalg.inv

计算矩阵的(乘法)逆。

给定一个方阵 a，返回满足 `dot(a, ainv) = dot(ainv, a) = eye(a.shape[0])` 的矩阵 ainv。



### 计算相关系数的函数

- **np.corrcoef(x,y)**





## 特征选择-函数方法与理解

### 过滤法-方差法

代码实现公式：
$$
var(X)=\frac{1}{n-1}\sum_{i=1}^{n}(x_i-μ)^{2
}
$$
对矩阵的深入理解

```python
var=1/(data.shape[0]-1)*(np.sum((np.matrix(data.values)-np.matrix(data.mean()))**2))
```

![](https://s1.ax1x.com/2022/03/20/qZS5ND.png)

![](https://s1.ax1x.com/2022/03/20/qZSLut.png)

- `np.matrix`把数组转化为矩阵
- `data.values`就是数表的值，就是去掉标签和索引的本身
- `data.mean`是把每一列的数值求平均值，返回一个行矩阵
- 数表(m*(n+1))-`data.mean`(1*(n+1)),就是每一行每一行地做减法

- `enumerate`返回下标和数值





### 过滤法—pearson相关系数

学习链接：[numpy.corrcoef — NumPy v1.22 Manual](https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html)



- `data.iloc[:,:]`返回一个数表，`data.loc[:,0]`返回数表的第一列所有元素

- 函数方法`x.columns.tolist()`把矩阵转化为列表

![](https://s1.ax1x.com/2022/03/20/qZicmn.png)

- `np.corrcoef()`

   语法：![](https://s1.ax1x.com/2022/03/20/qZFY3F.png)

## 标准化，归一化

### 归一化

核心思想是把数据范围缩小，限定在[0,1]之间

#### **算法：**

- 线性转化

$$
x'=\frac{x-min(x)}{max(x)-min(x)}
$$

$$
x'=\frac{x-average(x)}{max(x)-min(x)}
$$



- 对数函数转化

$$
y=log_{10}(x)
$$

#### **应用：**

- 无量钢化

​    归一化可以消除量纲对最终结果的影响，使不同变量具有可比性。比如两    个人体重差10KG，身高差0.02M，在衡量两个人的差别时体重的差距会把身高的差距完全掩盖，归一化之后就不会有这样的问题。

- 避免数值问题

​    不同的数据在不同列数据的**数量级相差过大**的话，计算起来大数的变化会掩盖掉小数的变化。

- 一些模型求解的需要

例如梯度下降法，如果不归一化，当学习率较大时，求解过程会呈之字形下降。学习率较小，则会产生直角形路线，不管怎么样，都不会是好路线

- 时间序列

进行log分析时，会将原本绝对化的时间序列归一化到某个基准时刻，形成相对时间序列，方便排查

- 收敛速度

加快求解过程中参数的收敛速度。

#### **特点：**

A、对不同特征维度进行伸缩变换
B、**改变原始数据的分布**，使得各个特征维度对目标函数的**影响权重归于一致**
C、对目标函数的**影响体现在数值上**
D、把有量纲表达式变为无量纲表达式



### 标准化

核心：将数据按照比例缩放

#### 算法：

- z-score标准化

$$
x'=\frac{x-average(x)}{μ}
$$

$$
μ^2=\frac{1}{m}\sum_{i=1}^{m}(x-average(x))^{2}
$$

#### 特点：

对不同特征维度的伸缩变化的目的是使不同度量之间的特征具有可比性，同时**不改变原始数据的分布**



**好处：**

- 改变原始数据的分布**，保持各个特征维度对目标函数的影响权重**

- 目标函数的影响体现在集合分布上
- 在已有样本足够多的情况下比较稳定



### 标准化与归一化区别

**首先**，都是用于特征缩放
**原理**上：
标准化适合大数据或量纲差异不大（不会出现一个大数样本主导）
归一化是解决数据权重不一致，影响定性分析时用。
用途上：
1、在分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用PCA技术进行降维的时候，**标准化**(Z-score standardization)表现更好。
2、在不涉及距离度量、**协方差**计算、数据不符合正太分布的时候，可以使用归一化方法。比如图像处理中，将RGB图像转换为灰度图像后将其值限定在[0 255]的范围。





## 残差图学习

百度百科：残差图是指以**某种残差为纵坐标**，以其他适宜的量作为横坐标的散点图



**常见的横坐标选取：**

- 因变量的拟合值
- 某自变量的观察值



**python实现残差图**

- 需要导入seaborn
- 函数方法：

```python
sns.residplot(x,y,lowess,color,data)
```





### 回归值与残差的残差图

为检验建立的多元线性回归模型是否合适，可以通过 **回归y'**与**残差**的散点图来检验



## ROC曲线和AUC

学习链接：[混淆矩阵、AUC、ROC，傻傻分不清楚？来看这篇就对了 - 掘金 (juejin.cn)](https://juejin.cn/post/6844904144541581319)



全称是：Receiver Operating Characteristic Curve

曲线的**横**坐标为**假阳性率（FPR）**，纵坐标为真阳性率
$$
TPR=\frac{TP}{TP+FN}
$$

- 在完成曲线后，需要AUC，就是ROC曲线下的面积大小。



AUC只需要沿着ROC横轴做积分即可，即求面积

